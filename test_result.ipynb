{"cells":[{"cell_type":"markdown","source":["## Test Result\n","\n","<mark>This notebook is called from an individual test case notebook; before you run this notebook, please `xmltodict` installed.</mark>  "],"metadata":{"nteract":{"transient":{"deleting":false}}},"id":"4476224d-74cb-4f6b-adc7-b929d75b08a6"},{"cell_type":"code","source":["from pyspark.sql.functions import when,col, explode,isnull,from_json\n","from pyspark.sql.types import StructType,StructField,StringType\n","import json\n","import xmltodict\n","\n","# convert xml to dict / json\n","dict_result=xmltodict.parse(out.getvalue())\n","json_result = json.loads(json.dumps(dict_result,indent=4).replace('@',''))\n","test_suites=json_result['testsuites']['testsuite']\n","\n","# create dataframe\n","df = spark.read.json(sc.parallelize([test_suites]))\n","\n","fail_schema = StructType([\n","  StructField(\"command\", StringType(), True),\n","  StructField(\"status\", StringType(),  True)\n","])\n","\n","explode_df= df.withColumn('ts',explode('testcase')).withColumn('fail',from_json(col('ts.failure.message'),fail_schema)).drop(col('testcase')).drop(col('ts.failure'))\n","\n","df_test_result=explode_df.select(col(\"errors\").alias(\"errorInSuite\"),col(\"failures\").alias(\"failedInSuite\"),col(\"name\").alias(\"suitename\"),\"skipped\",col(\"tests\").alias(\"totalTest\"),col(\"timestamp\").alias(\"executionTime\"),col(\"ts.name\").alias(\"testCaseName\"),col(\"ts.time\").alias(\"testCaseTime\"),col(\"fail.command\"))\n","\n","if (len(storage_account)>0 and len(result_container)>0):\n","    # save result to storage\n","    storage_path = f\"abfs://{result_container}@{storage_account}.dfs.core.windows.net/{TEST_RUN_ID}/{PLATFORM}/{TEST_SUITE}\"\n","    # write raw results\n","    df.write.parquet(f\"{storage_path}/{RAW_RESULT_FILE_NAME}\")\n","    # write transformed results\n","    df_test_result.write.parquet(f\"{storage_path}/{RESULT_FILE_NAME}\") \n","else:\n","    print(\"configure storage path to store results\")\n","    df_test_result.show(200,False)   "],"outputs":[],"execution_count":null,"metadata":{},"id":"b2e18793-18a2-40da-9005-89f931f608ea"}],"metadata":{"language_info":{"name":"python"},"kernelspec":{"name":"synapse_pyspark","display_name":"python"},"microsoft":{"host":{},"language":"python"},"widgets":{},"nteract":{"version":"nteract-front-end@1.0.0"},"save_output":true,"spark_compute":{"compute_id":"/trident/default","session_options":{"enableDebugMode":false,"conf":{}}},"notebook_environment":{},"synapse_widget":{"version":"0.1","state":{}}},"nbformat":4,"nbformat_minor":5}