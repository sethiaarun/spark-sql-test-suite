{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Test Cases for Auxiliary Statements used by Apache Spark\n",
        "**Spark SQL 3.3 Auxiliary Statements** \n",
        "https://spark.apache.org/docs/3.3.0/sql-ref-syntax.html#auxiliary-statements\n",
        "\n",
        "**<mark>Excludes</mark>:**\n",
        "\n",
        "\n",
        "To store these results configure data <mark>**storage account and container**</mark>."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install unittest-xml-reporting xmltodict"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Configure Result Storage Location"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "storage_account=\"\"\n",
        "result_container=\"\"\n",
        "# change this to accessible URL\n",
        "add_jar_url = \"https://github.com/sethiaarun/azureSynapseSparkUnitTest/releases/download/1.0/businessfunction-1.0.jar\"\n",
        "add_file_url = \"https://github.com/apache/spark/blob/master/examples/src/main/python/wordcount.py\"\n",
        "archive_file_url = \"https://resources.lendingclub.com/LoanStats3a.csv.zip\""
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Initialize Common Variables for the test run"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "# Don't change these variables\n",
        "TEST_SUITE= \"SPARK_SQL_AUX_STATEMENTS\"\n",
        "RESULT_FILE_NAME=\"aux_stmt_test_result.parquet\"\n",
        "RAW_RESULT_FILE_NAME=\"raw_aux_stmt_test_result.parquet\"\n",
        "# Test Run ID\n",
        "TEST_RUN_ID= round(time.time()*1000)\n",
        "# Test platform\n",
        "PLATFORM = \"nameoftheplatform\"\n",
        "# Prefix for all tables\n",
        "PREFIX = PLATFORM\n",
        "SUFFIX = TEST_RUN_ID\n",
        "# Spark SQL function\n",
        "sql=spark.sql"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Set Common Spark Configurations"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sql(\"set hive.exec.dynamic.partition.mode=nonstrict\")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Table Auxiliary Statements - DELTA FORMAT"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import unittest\n",
        "from pyspark.sql.utils import AnalysisException\n",
        "\n",
        "class AuxDeltaTableStmtTest(unittest.TestCase):\n",
        "    \"\"\"Auxiliary Statements test cases - using delta table\"\"\"\n",
        "    \n",
        "    table_name = f\"{PREFIX}_student_aux_stmt_delta_table_{SUFFIX}\"\n",
        "    view_name = f\"{PREFIX}_student_aux_stmt_delta_table_view_{SUFFIX}\"      \n",
        "   \n",
        "    @classmethod\n",
        "    def setUpClass(cls):\n",
        "        sql_cmd = f\"CREATE TABLE {cls.table_name} (id INT, name STRING) USING delta PARTITIONED BY (age INT) \\\n",
        "                          TBLPROPERTIES ('created.by.user' = 'Testcases')\"\n",
        "        try:\n",
        "            sql(sql_cmd)\n",
        "            sql(f\"INSERT INTO {cls.table_name} VALUES \\\n",
        "                 (1,'a',10),(2,'b',20),(3,'c',30);\")\n",
        "        except Exception as ex:\n",
        "            msg={'command':'AlterTable:Setup failed','status':'fail'}\n",
        "            cls.fail(f\"{msg}\")\n",
        "\n",
        "    \n",
        "    def test_delta_aux_stmt_001_show_column(self):\n",
        "        \"\"\"Show Columns\"\"\"\n",
        "        sql_cmd = f\"SHOW COLUMNS IN {self.table_name};\"\n",
        "        try:\n",
        "            row_count=sql(sql_cmd).count()\n",
        "            self.assertEqual(row_count,3)\n",
        "        except Exception as ex:\n",
        "            msg={'command':'SHOW COLUMNS for Delta Table','status':'fail'}\n",
        "            self.fail(f\"{msg}\")\n",
        "    \n",
        "    def test_delta_aux_stmt_002_show_create_table_stmt(self):\n",
        "        \"\"\"Show Create Table Statement\"\"\"\n",
        "        sql_cmd = f\"SHOW CREATE TABLE {self.table_name} AS SERDE;\"\n",
        "        try:\n",
        "            row_count=sql(sql_cmd).select(\"createtab_stmt\").count()\n",
        "            self.assertEqual(row_count,1)\n",
        "        except Exception as ex:\n",
        "            msg={'command':'SHOW CREATE TABLE Statement for Delta Table','status':'fail'}\n",
        "            self.fail(f\"{msg}\")\n",
        "\n",
        "    def test_delta_aux_stmt_003_show_partition_table_stmt(self):\n",
        "        \"\"\"Show Partition Table Statement\"\"\"\n",
        "        sql_cmd = f\"SHOW PARTITIONS {self.table_name};\"\n",
        "        try:\n",
        "            row_count=sql(sql_cmd)\n",
        "            self.assertEqual(row_count.select(\"partition\").count(),3)\n",
        "            row_count=sql(f\"SHOW PARTITIONS {self.table_name} PARTITION (age = '10');\").select(\"partition\").count()\n",
        "            self.assertEqual(row_count,1)\n",
        "        except Exception as ex:\n",
        "            msg={'command':'SHOW PARTITIONS Table Statement for Delta Table','status':'fail'}\n",
        "            self.fail(f\"{msg}\")\n",
        "\n",
        "    def test_delta_aux_stmt_004_show_table_extended_stmt(self):\n",
        "        \"\"\"Show Table Extended Table Statement\"\"\"\n",
        "        sql_cmd = f\"SHOW TABLE EXTENDED  LIKE '{self.table_name}';\"\n",
        "        try:\n",
        "            row_count=sql(sql_cmd).select(\"tableName\").count()\n",
        "            self.assertEqual(row_count,1)\n",
        "        except Exception as ex:\n",
        "            msg={'command':'SHOW TABLE EXTENDED LIKE  Statement for Delta Table','status':'fail'}\n",
        "            self.fail(f\"{msg}\")\n",
        "\n",
        "    def test_delta_aux_stmt_005_show_table_extended_partition_stmt(self):\n",
        "        \"\"\"Show Table Extended Table Statement with Partition\"\"\"\n",
        "        sql_cmd = f\"SHOW TABLE EXTENDED  LIKE '{self.table_name}' PARTITION (age=10);\"\n",
        "        try:\n",
        "            row_count=sql(sql_cmd).select(\"tableName\").count()\n",
        "            self.assertEqual(row_count,1)\n",
        "        except Exception as ex:\n",
        "            msg={'command':'SHOW TABLE EXTENDED LIKE PARTITION for Delta Table','status':'fail'}\n",
        "            self.fail(f\"{msg}\")\n",
        "\n",
        "    def test_delta_aux_stmt_006_show_tables_stmt(self):\n",
        "        \"\"\"Show Table Statement\"\"\"\n",
        "        sql_cmd1 = f\"SHOW TABLES;\"\n",
        "        sql_cmd2 = f\"SHOW TABLES LIKE 'student*|test*';\"\n",
        "        try:\n",
        "            row_count=sql(sql_cmd1).select(\"tableName\").count()\n",
        "            self.assertGreaterEqual(row_count,1)\n",
        "            row_count=sql(sql_cmd2).select(\"tableName\").count()\n",
        "            self.assertGreaterEqual(row_count,1)\n",
        "        except Exception as ex:\n",
        "            msg={'command':'SHOW TABLES and SHOW TABLES LIKE for Delta Table','status':'fail'}\n",
        "            self.fail(f\"{msg}\")\n",
        "\n",
        "    def test_delta_aux_stmt_007_show_tables_prop_stmt(self):\n",
        "        \"\"\"Show Table Statement\"\"\"\n",
        "        sql_cmd1 = f\"SHOW TBLPROPERTIES {self.table_name};\"\n",
        "        sql_cmd2 = f\"SHOW TBLPROPERTIES {self.table_name} (created.by.user);\"\n",
        "        try:\n",
        "            row_count=sql(sql_cmd1).select(\"key\").count()\n",
        "            self.assertGreaterEqual(row_count,1)\n",
        "            row_count=sql(sql_cmd2).select(\"value\").count()\n",
        "            self.assertGreaterEqual(row_count,1)\n",
        "        except Exception as ex:\n",
        "            msg={'command':'SHOW TBLPROPERTIES for Delta Table','status':'fail'}\n",
        "            self.fail(f\"{msg}\")\n",
        "    \n",
        "    def test_delta_aux_stmt_008_create_view(self):\n",
        "        \"\"\"create view\"\"\"\n",
        "        sql_cmd = f\"CREATE OR REPLACE VIEW  {self.view_name} (id COMMENT 'ID', name COMMENT 'Name') \\\n",
        "                    COMMENT 'View for student table' \\\n",
        "                    AS SELECT ID,name FROM {self.table_name};\"\n",
        "        try:\n",
        "            sql(sql_cmd)\n",
        "        except Exception as ex:\n",
        "            msg={'command':'CREATE OR REPLACE VIEW for Delta Table','status':'fail'}\n",
        "            self.fail(f\"{msg}\")\n",
        "    \n",
        "    def test_delta_aux_stmt_009_show_view(self):\n",
        "        \"\"\"show view\"\"\"\n",
        "        try:\n",
        "            view_exist=sql(f\"SHOW VIEWS\").filter(f\"viewName='{self.view_name}'\").count()\n",
        "            self.assertEqual(view_exist,1)\n",
        "        except Exception as ex:\n",
        "            msg={'command':'SHOW VIEWS for Delta Table','status':'fail'}\n",
        "            self.fail(f\"{msg}\")\n",
        "\n",
        "    \n",
        "    def test_delta_aux_stmt_010_cache_table_stmt(self):\n",
        "        \"\"\"Cache and UnCache Table\"\"\"\n",
        "        cache_table_name = f\"{PREFIX}_student_aux_stmt_delta_table_cache_{SUFFIX}\"\n",
        "        sql_cmd = f\"CACHE TABLE {cache_table_name}  OPTIONS ('storageLevel' 'DISK_ONLY') SELECT * FROM {self.table_name}\"\n",
        "        uncache_sql_cmd = f\"UNCACHE TABLE {cache_table_name}\"\n",
        "        try:\n",
        "            sql(sql_cmd)\n",
        "            row_count=sql(f\"SELECT * FROM {cache_table_name}\").count()\n",
        "            self.assertGreaterEqual(row_count,1)\n",
        "            sql(uncache_sql_cmd)\n",
        "        except Exception as ex:\n",
        "            msg={'command':'CACHE TABLE and UNCACHE TABLE for Delta Table','status':'fail'}\n",
        "            self.fail(f\"{msg}\")\n",
        "\n",
        "        finally:\n",
        "            sql(f\"DROP TABLE IF EXISTS {cache_table_name}\")\n",
        "\n",
        "    def test_delta_aux_stmt_011_stat_noscan(self):\n",
        "        \"\"\"Delta Table  Analyze Table Compute Statistics NoScan\"\"\"\n",
        "        sql_cmd = f\"ANALYZE TABLE {self.table_name} COMPUTE STATISTICS NOSCAN;\"\n",
        "        try:\n",
        "            sql(sql_cmd)\n",
        "            row_count=sql(f\"DESC EXTENDED {self.table_name}\").where(\"col_name='Statistics'\").count()\n",
        "            self.assertEqual(row_count,1)\n",
        "        except Exception as ex:\n",
        "            msg={'command':'ANALYZE TABLE COMPUTE STATISTICS NOSCAN and DESC EXTENDED for Delta Table','status':'fail'}\n",
        "            self.fail(f\"{msg}\")\n",
        "    \n",
        "    def test_delta_aux_stmt_012_describe_query(self):\n",
        "        \"\"\"Describe query\"\"\"\n",
        "        sql_cmd = f\"DESCRIBE QUERY SELECT age, sum(age) FROM {self.table_name} GROUP BY age;\"\n",
        "        try:\n",
        "            row_count=sql(sql_cmd).select(\"col_name\").count()\n",
        "            self.assertEqual(row_count,2)\n",
        "        except Exception as ex:\n",
        "            msg={'command':'DESCRIBE QUERY for Delta format','status':'fail'}\n",
        "            self.fail(f\"{msg}\")\n",
        "\n",
        "    def test_delta_aux_stmt_012_describe_table(self):\n",
        "        \"\"\"Describe table\"\"\"\n",
        "        sql_cmd = f\"DESCRIBE TABLE {self.table_name}\"\n",
        "        try:\n",
        "            row_count=sql(sql_cmd).select(\"col_name\").count()\n",
        "            self.assertGreaterEqual(row_count,1)\n",
        "        except Exception as ex:\n",
        "            msg={'command':'DESCRIBE QUERY for Delta format','status':'fail'}\n",
        "            self.fail(f\"{msg}\")\n",
        "\n",
        "\n",
        "    @classmethod\n",
        "    def tearDownClass(cls):\n",
        "        \"\"\"tear down\"\"\"\n",
        "        try:\n",
        "            sql(f\"DROP TABLE IF EXISTS {cls.table_name}\")\n",
        "        except Exception as e:\n",
        "            print(f\"table drop failed: {cls.table_name}\")\n",
        "\n",
        "        try:\n",
        "            sql(f\"DROP VIEW IF EXISTS {cls.view_name}\")\n",
        "        except Exception as e:\n",
        "            print(f\"View drop failed: {cls.view_name}\")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Table Auxiliary Statements - DEFAULT FORMAT"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import unittest\n",
        "from pyspark.sql.utils import AnalysisException\n",
        "\n",
        "class AuxTableStmtTest(unittest.TestCase):\n",
        "    \"\"\"Auxiliary Statements test cases - using default format\"\"\"\n",
        "    \n",
        "    table_name = f\"{PREFIX}_student_aux_stmt_default_table_{SUFFIX}\"\n",
        "    view_name = f\"{PREFIX}_student_aux_stmt_default_table_view_{SUFFIX}\"\n",
        "   \n",
        "    @classmethod\n",
        "    def setUpClass(cls):\n",
        "        sql_cmd = f\"CREATE TABLE {cls.table_name} (id INT, name STRING) PARTITIONED BY (age INT) \\\n",
        "                          TBLPROPERTIES ('created.by.user' = 'Testcases')\"\n",
        "        try:\n",
        "            sql(sql_cmd)\n",
        "            sql(f\"INSERT INTO {cls.table_name} VALUES \\\n",
        "                 (1,'a',10),(2,'b',20),(3,'c',30);\")\n",
        "        except Exception as ex:\n",
        "            msg={'command':'AlterTable:Setup failed','status':'fail'}\n",
        "            cls.fail(f\"{msg}\")\n",
        "\n",
        "    \n",
        "    def test_default_aux_stmt_001_show_column(self):\n",
        "        \"\"\"Show Columns\"\"\"\n",
        "        sql_cmd = f\"SHOW COLUMNS IN {self.table_name};\"\n",
        "        try:\n",
        "            row_count=sql(sql_cmd).count()\n",
        "            self.assertEqual(row_count,3)\n",
        "        except Exception as ex:\n",
        "            msg={'command':'SHOW COLUMNS for Default format','status':'fail'}\n",
        "            self.fail(f\"{msg}\")\n",
        "    \n",
        "    def test_default_aux_stmt_002_show_create_table_stmt(self):\n",
        "        \"\"\"Show Create Table Statement\"\"\"\n",
        "        sql_cmd = f\"SHOW CREATE TABLE {self.table_name} AS SERDE;\"\n",
        "        try:\n",
        "            row_count=sql(sql_cmd).select(\"createtab_stmt\").count()\n",
        "            self.assertEqual(row_count,1)\n",
        "        except Exception as ex:\n",
        "            msg={'command':'SHOW CREATE TABLE Statement for Default format','status':'fail'}\n",
        "            self.fail(f\"{msg}\")\n",
        "\n",
        "    def test_default_aux_stmt_003_show_partition_table_stmt(self):\n",
        "        \"\"\"Show Partition Table Statement\"\"\"\n",
        "        sql_cmd = f\"SHOW PARTITIONS {self.table_name};\"\n",
        "        try:\n",
        "            row_count=sql(sql_cmd)\n",
        "            self.assertEqual(row_count.select(\"partition\").count(),3)\n",
        "            row_count=sql(f\"SHOW PARTITIONS {self.table_name} PARTITION (age = '10');\").select(\"partition\").count()\n",
        "            self.assertEqual(row_count,1)\n",
        "        except Exception as ex:\n",
        "            msg={'command':'SHOW PARTITIONS Table Statement for Default format','status':'fail'}\n",
        "            self.fail(f\"{msg}\")\n",
        "\n",
        "    def test_default_aux_stmt_004_show_table_extended_stmt(self):\n",
        "        \"\"\"Show Table Extended Table Statement\"\"\"\n",
        "        sql_cmd = f\"SHOW TABLE EXTENDED  LIKE '{self.table_name}';\"\n",
        "        try:\n",
        "            row_count=sql(sql_cmd).select(\"tableName\").count()\n",
        "            self.assertEqual(row_count,1)\n",
        "        except Exception as ex:\n",
        "            msg={'command':'SHOW TABLE EXTENDED LIKE  Statement for Delta Table','status':'fail'}\n",
        "            self.fail(f\"{msg}\")\n",
        "\n",
        "    def test_default_aux_stmt_005_show_table_extended_partition_stmt(self):\n",
        "        \"\"\"Show Table Extended Table Statement with Partition\"\"\"\n",
        "        sql_cmd = f\"SHOW TABLE EXTENDED  LIKE '{self.table_name}' PARTITION (age=10);\"\n",
        "        try:\n",
        "            row_count=sql(sql_cmd).select(\"tableName\").count()\n",
        "            self.assertEqual(row_count,1)\n",
        "        except Exception as ex:\n",
        "            msg={'command':'SHOW TABLE EXTENDED LIKE PARTITION for Default format','status':'fail'}\n",
        "            self.fail(f\"{msg}\")\n",
        "\n",
        "    def test_default_aux_stmt_006_show_tables_stmt(self):\n",
        "        \"\"\"Show Table Statement\"\"\"\n",
        "        sql_cmd1 = f\"SHOW TABLES;\"\n",
        "        sql_cmd2 = f\"SHOW TABLES LIKE 'student*|test*';\"\n",
        "        try:\n",
        "            row_count=sql(sql_cmd1).select(\"tableName\").count()\n",
        "            self.assertGreaterEqual(row_count,1)\n",
        "            row_count=sql(sql_cmd2).select(\"tableName\").count()\n",
        "            self.assertGreaterEqual(row_count,1)\n",
        "        except Exception as ex:\n",
        "            msg={'command':'SHOW TABLES and SHOW TABLES LIKE for Default format','status':'fail'}\n",
        "            self.fail(f\"{msg}\")\n",
        "\n",
        "    def test_default_aux_stmt_007_show_tables_prop_stmt(self):\n",
        "        \"\"\"Show Table Statement\"\"\"\n",
        "        sql_cmd1 = f\"SHOW TBLPROPERTIES {self.table_name};\"\n",
        "        sql_cmd2 = f\"SHOW TBLPROPERTIES {self.table_name} (created.by.user);\"\n",
        "        try:\n",
        "            row_count=sql(sql_cmd1).select(\"key\").count()\n",
        "            self.assertGreaterEqual(row_count,1)\n",
        "            row_count=sql(sql_cmd2).select(\"value\").count()\n",
        "            self.assertGreaterEqual(row_count,1)\n",
        "        except Exception as ex:\n",
        "            msg={'command':'SHOW TBLPROPERTIES for Default format','status':'fail'}\n",
        "            self.fail(f\"{msg}\")\n",
        "    \n",
        "    def test_default_aux_stmt_008_create_view(self):\n",
        "        \"\"\"create view\"\"\"\n",
        "        sql_cmd = f\"CREATE OR REPLACE VIEW  {self.view_name} (id COMMENT 'ID', name COMMENT 'Name') \\\n",
        "                    COMMENT 'View for student table' \\\n",
        "                    AS SELECT ID,name FROM {self.table_name};\"\n",
        "        try:\n",
        "            sql(sql_cmd)\n",
        "        except Exception as ex:\n",
        "            msg={'command':'CREATE OR REPLACE VIEW for Default format','status':'fail'}\n",
        "            self.fail(f\"{msg}\")\n",
        "    \n",
        "    def test_default_aux_stmt_009_show_view(self):\n",
        "        \"\"\"show view\"\"\"\n",
        "        try:\n",
        "            view_exist=sql(f\"SHOW VIEWS\").filter(f\"viewName='{self.view_name}'\").count()\n",
        "            self.assertEqual(view_exist,1)\n",
        "        except Exception as ex:\n",
        "            msg={'command':'SHOW VIEWS for Default format','status':'fail'}\n",
        "            self.fail(f\"{msg}\")\n",
        "\n",
        "    \n",
        "    def test_default_aux_stmt_010_cache_table_stmt(self):\n",
        "        \"\"\"Cache and UnCache Table\"\"\"\n",
        "        sql_cmd = f\"CACHE TABLE {self.cache_table_name}  OPTIONS ('storageLevel' 'DISK_ONLY') SELECT * FROM {self.table_name}\"\n",
        "        uncache_sql_cmd = f\"UNCACHE TABLE {self.cache_table_name}\"\n",
        "        try:\n",
        "            sql(sql_cmd)\n",
        "            row_count=sql(f\"SELECT * FROM {self.cache_table_name}\").count()\n",
        "            self.assertGreaterEqual(row_count,1)\n",
        "            sql(uncache_sql_cmd)\n",
        "        except Exception as ex:\n",
        "            msg={'command':'CACHE TABLE and UNCACHE TABLE for Default format','status':'fail'}\n",
        "            self.fail(f\"{msg}\")\n",
        "\n",
        "    def test_default_aux_stmt_011_stat_noscan(self):\n",
        "        \"\"\"Analyze Table Compute Statistics NoScan\"\"\"\n",
        "        sql_cmd = f\"ANALYZE TABLE {self.table_name} COMPUTE STATISTICS NOSCAN;\"\n",
        "        try:\n",
        "            sql(sql_cmd)\n",
        "            row_count=sql(f\"DESC EXTENDED {self.table_name}\").where(\"col_name='Statistics'\").count()\n",
        "            self.assertEqual(row_count,1)\n",
        "        except Exception as ex:\n",
        "            msg={'command':'ANALYZE TABLE COMPUTE STATISTICS NOSCAN and DESC EXTENDED for Default format','status':'fail'}\n",
        "            self.fail(f\"{msg}\")\n",
        "\n",
        "    def test_default_aux_stmt_012_describe_query(self):\n",
        "        \"\"\"Describe query\"\"\"\n",
        "        sql_cmd = f\"DESCRIBE QUERY SELECT age, sum(age) FROM {self.table_name} GROUP BY age;\"\n",
        "        try:\n",
        "            row_count=sql(sql_cmd).select(\"col_name\").count()\n",
        "            self.assertEqual(row_count,2)\n",
        "        except Exception as ex:\n",
        "            msg={'command':'DESCRIBE QUERY for Default format','status':'fail'}\n",
        "            self.fail(f\"{msg}\")\n",
        "\n",
        "    @classmethod\n",
        "    def tearDownClass(cls):\n",
        "        \"\"\"tear down\"\"\"\n",
        "        try:\n",
        "            sql(f\"DROP TABLE IF EXISTS {cls.table_name}\")\n",
        "        except Exception as e:\n",
        "            print(f\"table drop failed: {cls.table_name}\")\n",
        "\n",
        "        try:\n",
        "            sql(f\"DROP TABLE IF EXISTS {cls.cache_table_name}\")\n",
        "        except Exception as e:\n",
        "            print(f\"table drop failed: {cls.cache_table_name}\")\n",
        "        \n",
        "        try:\n",
        "            sql(f\"DROP VIEW  IF EXISTS {cls.view_name}\")\n",
        "        except Exception as e:\n",
        "            print(f\"View drop failed: {cls.view_name}\")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Analyze Table Statements\n",
        "\n",
        "**Analyze Tables is <mark>not supported for V2 tables.**"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import unittest\n",
        "from pyspark.sql.utils import AnalysisException\n",
        "\n",
        "class AnalyzeTableStmtTest(unittest.TestCase):\n",
        "    \"\"\"Analyze Table Statements test cases for Non Delta Tables\"\"\"\n",
        "    \n",
        "    table_name = f\"{PREFIX}_student_analyze_table_{SUFFIX}\"   \n",
        "   \n",
        "    @classmethod\n",
        "    def setUpClass(cls):\n",
        "        sql_cmd = f\"CREATE TABLE {cls.table_name} (id INT, name STRING) PARTITIONED BY (age INT) \\\n",
        "                          TBLPROPERTIES ('created.by.user' = 'Testcases')\"\n",
        "        try:\n",
        "            sql(sql_cmd)\n",
        "            sql(f\"INSERT INTO {cls.table_name} VALUES \\\n",
        "                 (1,'a',10),(2,'b',20),(3,'c',30);\")\n",
        "        except Exception as ex:\n",
        "            msg={'command':'AnalyzeTable:Setup failed','status':'fail'}\n",
        "            cls.fail(f\"{msg}\")\n",
        "\n",
        "    \n",
        "    def test_analyze_table_stmt_001_stat_partition(self):\n",
        "        \"\"\"Analyze Table Compute Statistics with partition\"\"\"\n",
        "        sql_cmd = f\"ANALYZE TABLE {self.table_name} PARTITION (age=10) COMPUTE STATISTICS;\"\n",
        "        try:\n",
        "            sql(sql_cmd)\n",
        "            row_count=sql(f\"DESC EXTENDED {self.table_name} PARTITION (age=10)\").where(\"col_name='Partition Statistics'\").count()\n",
        "            self.assertEqual(row_count,1)\n",
        "        except Exception as ex:\n",
        "            msg={'command':'ANALYZE TABLE PARTITION COMPUTE STATISTICS for default format','status':'fail'}\n",
        "            self.fail(f\"{msg}\")\n",
        "    \n",
        "    def test_analyze_table_stmt_002_stat_for_columns(self):\n",
        "        \"\"\"Analyze Table Compute Statistics for Columns\"\"\"\n",
        "        sql_cmd = f\"ANALYZE TABLE {self.table_name} COMPUTE STATISTICS FOR COLUMNS name\"\n",
        "        try:\n",
        "            sql(sql_cmd)\n",
        "            row_count=sql(f\"DESC EXTENDED {self.table_name} name\").where(\"info_name='col_name'\").count()\n",
        "            self.assertEqual(row_count,1)\n",
        "        except Exception as ex:\n",
        "            msg={'command':'ANALYZE TABLE COMPUTE STATISTICS FOR COLUMNS for default format','status':'fail'}\n",
        "            self.fail(f\"{msg}\")\n",
        "    \n",
        "\n",
        "    @classmethod\n",
        "    def tearDownClass(cls):\n",
        "        \"\"\"tear down\"\"\"\n",
        "        try:\n",
        "            sql(f\"DROP TABLE IF EXISTS {cls.table_name}\")\n",
        "        except Exception as e:\n",
        "            print(f\"table drop failed: {cls.table_name}\")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Miscellaneous Auxiliary Statements"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import unittest\n",
        "from pyspark.sql.utils import AnalysisException\n",
        "\n",
        "class AuxMiscStmtTest(unittest.TestCase):\n",
        "    \"\"\"Auxiliary miscellaneous Statements\"\"\"\n",
        "    \n",
        "   \n",
        "    def test_aux_stmt_001_show_schema(self):\n",
        "        \"\"\"Show Schema\"\"\"\n",
        "        sql_cmd = f\"SHOW SCHEMAS;\"\n",
        "        try:\n",
        "            row_count=sql(sql_cmd).count()\n",
        "            self.assertGreaterEqual(row_count,0)\n",
        "        except Exception as ex:\n",
        "            msg={'command':'SHOW SCHEMAS','status':'fail'}\n",
        "            self.fail(f\"{msg}\")\n",
        "    \n",
        "    def test_aux_stmt_001_show_databases(self):\n",
        "        \"\"\"Show Databases\"\"\"\n",
        "        sql_cmd = f\"SHOW DATABASES;\"\n",
        "        try:\n",
        "            row_count=sql(sql_cmd).count()\n",
        "            self.assertGreaterEqual(row_count,1)\n",
        "        except Exception as ex:\n",
        "            msg={'command':'SHOW DATABASES','status':'fail'}\n",
        "            self.fail(f\"{msg}\")   \n",
        "\n",
        "    def test_aux_stmt_002_desc_databases(self):\n",
        "        \"\"\"describe Databases\"\"\"\n",
        "        sql_cmd = f\"SHOW DATABASES;\"\n",
        "        msg={'command':'DESC DATABASE','status':'fail'}\n",
        "        try:\n",
        "            databases=sql(sql_cmd).select('namespace').rdd.flatMap(lambda x: x).collect()\n",
        "            if len(databases)>0:\n",
        "                row_count=sql(f\"DESC DATABASE {databases[0]}\").where(f\"info_value='{databases[0]}'\").count()\n",
        "                self.assertEqual(row_count,1)\n",
        "            else:\n",
        "                self.fail(f\"{msg}\")  \n",
        "        except Exception as ex:\n",
        "            self.fail(f\"{msg}\")   \n",
        "\n",
        "    #sql(\"SHOW DATABASES\").select('namespace').rdd.flatMap(lambda x: x).collect()\n",
        "    def test_aux_stmt_003_show_functions(self):\n",
        "        \"\"\"Show Functions\"\"\"\n",
        "        sql_cmd = f\"SHOW FUNCTIONS explode;\"\n",
        "        try:\n",
        "            row_count=sql(sql_cmd).count()\n",
        "            self.assertEqual(row_count,1)\n",
        "            row_count=sql(\"SHOW FUNCTIONS LIKE 't*'\").count()\n",
        "            self.assertGreaterEqual(row_count,1)\n",
        "            row_count = sql(\"SHOW FUNCTIONS LIKE 'yea*|windo*'\").count()\n",
        "            self.assertGreaterEqual(row_count,1)\n",
        "        except Exception as ex:\n",
        "            msg={'command':'SHOW FUNCTIONS and SHOW FUNCTIONS LIKE','status':'fail'}\n",
        "            self.fail(f\"{msg}\")   \n",
        "\n",
        "    def test_aux_stmt_004_desc_functions(self):\n",
        "        \"\"\"describe functions\"\"\"\n",
        "        sql_cmd = f\"DESC FUNCTION EXTENDED abs\"\n",
        "        try:\n",
        "            row_count=sql(sql_cmd).select('function_desc').count()\n",
        "            self.assertGreaterEqual(row_count,1)\n",
        "        except Exception as ex:\n",
        "            msg={'command':'DESC FUNCTION','status':'fail'}\n",
        "            self.fail(f\"{msg}\")   \n",
        "\n",
        "    def test_aux_stmt_005_add_list_jar(self):\n",
        "        \"\"\"Add and List Jar Statement\"\"\"\n",
        "        sql_cmd1 = f\"ADD JAR {add_jar_url}\"\n",
        "        sql_cmd2= f\"LIST JAR {add_jar_url}\"\n",
        "        try:\n",
        "            sql(sql_cmd1)\n",
        "            row_count=sql(sql_cmd2).count()\n",
        "            self.assertGreaterEqual(row_count,1)\n",
        "        except Exception as ex:\n",
        "            msg={'command':'ADD JAR and LIST JAR','status':'fail'}\n",
        "            self.fail(f\"{msg}\")   \n",
        "\n",
        "    def test_aux_stmt_006_add_file(self):\n",
        "        \"\"\"Add and List File Statement\"\"\"\n",
        "        sql_cmd1 = f\"ADD FILE {add_file_url}\"\n",
        "        sql_cmd2= f\"LIST FILE {add_file_url}\"\n",
        "        try:\n",
        "            sql(sql_cmd1)\n",
        "            row_count=sql(sql_cmd2).count()\n",
        "            self.assertGreaterEqual(row_count,1)\n",
        "        except Exception as ex:\n",
        "            msg={'command':'ADD FILE and LIST FILE','status':'fail'}\n",
        "            self.fail(f\"{msg}\")   \n",
        "\n",
        "    def test_aux_stmt_007_add_archive_file(self):\n",
        "        \"\"\"Add and List File Statement\"\"\"\n",
        "        sql_cmd1 = f\"ADD ARCHIVE {archive_file_url}\"\n",
        "        sql_cmd2= f\"LIST ARCHIVE {archive_file_url}\"\n",
        "        try:\n",
        "            sql(sql_cmd1)\n",
        "            row_count=sql(sql_cmd2).count()\n",
        "            self.assertGreaterEqual(row_count,1)\n",
        "        except Exception as ex:\n",
        "            msg={'command':'ADD ARCHIVE and LIST ARCHIVE','status':'fail'}\n",
        "            self.fail(f\"{msg}\")   \n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Execute Test Cases"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import io\n",
        "import xmlrunner\n",
        "loader = unittest.TestLoader()\n",
        "suite  = unittest.TestSuite()\n",
        "\n",
        "# add tests to the test suite\n",
        "suite.addTests(loader.loadTestsFromTestCase(AnalyzeTableStmtTest))\n",
        "suite.addTests(loader.loadTestsFromTestCase(AuxDeltaTableStmtTest))\n",
        "suite.addTest(loader.loadTestsFromTestCase(AuxMiscStmtTest))\n",
        "suite.addTest(loader.loadTestsFromTestCase(AnalyzeTableStmtTest))\n",
        "\n",
        "# initialize a runner, pass it your suite and run it\n",
        "out = io.BytesIO()\n",
        "runner = xmlrunner.XMLTestRunner(output=out)\n",
        "result = runner.run(suite)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Report for Test"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import col, explode,isnull,from_json, expr, to_json, coalesce, lit\n",
        "from pyspark.sql.types import StructType,StructField,StringType\n",
        "import json\n",
        "import xmltodict\n",
        "\n",
        "dict_result=xmltodict.parse(out.getvalue())\n",
        "json_result = json.loads(json.dumps(dict_result,indent=4).replace('@',''))\n",
        "test_suites=json_result['testsuites']['testsuite']\n",
        "\n",
        "df = spark.read.json(sc.parallelize([test_suites]))\n",
        "fail_schema = StructType([\n",
        "  StructField(\"command\", StringType(), True),\n",
        "  StructField(\"status\", StringType(),  True)\n",
        "])\n",
        "\n",
        "test_cases_df= df.withColumn('ts',explode('testcase')).drop(col('testcase'))\n",
        "\n",
        "if \"failure:\" in test_cases_df.schema.simpleString():\n",
        " explode_df= test_cases_df.withColumn('fail',from_json(col('ts.failure.message'),fail_schema)).drop(col('ts.failure'))\n",
        "else:\n",
        " explode_df= test_cases_df.withColumn(\"fail\",from_json(expr(\"to_json(named_struct('command', '', 'status', 'pass'))\"),fail_schema))\n",
        " \n",
        "df_test_result=explode_df.select(col(\"errors\").alias(\"errorInSuite\"),col(\"failures\").alias(\"failedInSuite\"),col(\"name\").alias(\"suitename\"),\\\n",
        "      \"skipped\",col(\"tests\").alias(\"totalTest\"), col(\"timestamp\").alias(\"executionTime\"),col(\"ts.name\").alias(\"testCaseName\"), \\\n",
        "       col(\"ts.time\").alias(\"testCaseTime\"),coalesce(col(\"fail.command\"), lit(\"\")).alias(\"failcommand\"),coalesce(col(\"fail.status\"), lit(\"pass\")).alias(\"status\"))\n",
        "\n",
        "df_test_result_summary=df_test_result.select(col('errorInSuite'),col('failedInSuite'),col('suitename'),col('skipped'),col('totaltest')).distinct()\n",
        "\n",
        "if (len(storage_account)>0 and len(result_container)>0):\n",
        "    # save result to storage\n",
        "    storage_path = f\"abfs://{result_container}@{storage_account}.dfs.core.windows.net/{TEST_RUN_ID}/{PLATFORM}/{TEST_SUITE}\"\n",
        "    # write raw results\n",
        "    df.write.parquet(f\"{storage_path}/{RAW_RESULT_FILE_NAME}\")\n",
        "    # write transformed results\n",
        "    df_test_result.write.parquet(f\"{storage_path}/{RESULT_FILE_NAME}\") \n",
        "    # write transformed results\n",
        "    df_test_result_summary.write.parquet(f\"{storage_path}/{RESULT_FILE_NAME}_summary\") \n",
        "else:\n",
        "    print(\"configure storage path to store results\")\n",
        "    df_test_result.show(200,False)    \n",
        "    df_test_result_summary.show(100,False)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "synapse_pyspark",
      "language": "Python",
      "display_name": "Synapse PySpark"
    },
    "language_info": {
      "name": "python"
    },
    "kernel_info": {
      "name": "synapse_pyspark"
    },
    "save_output": false,
    "synapse_widget": {
      "version": "0.1",
      "state": {}
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}