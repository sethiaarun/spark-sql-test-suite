{"cells":[{"cell_type":"markdown","source":["## Test Cases for Auxiliary Statements used by Apache Spark\n","**Spark SQL 3.3 Auxiliary Statements** \n","https://spark.apache.org/docs/3.3.0/sql-ref-syntax.html#auxiliary-statements\n","\n","**<mark>Excludes</mark>:**\n","\n","\n","To store these results configure data <mark>**storage account and container**</mark>."],"metadata":{"nteract":{"transient":{"deleting":false}}},"id":"b2131b90-dc2e-4e8e-8626-56baca1cd682"},{"cell_type":"code","source":["!pip install unittest-xml-reporting xmltodict"],"outputs":[],"execution_count":11,"metadata":{},"id":"3d5975b8-77ab-48bd-ae26-53b86cf1f045"},{"cell_type":"markdown","source":["## Configure Result Storage Location"],"metadata":{"nteract":{"transient":{"deleting":false}}},"id":"3f8d323a-fc16-46be-b608-7a1a391cff91"},{"cell_type":"code","source":["storage_account=\"\"\n","result_container=\"\"\n","# change this to accessible URL\n","add_jar_url = \"https://github.com/sethiaarun/azureSynapseSparkUnitTest/releases/download/1.0/businessfunction-1.0.jar\"\n","add_file_url = \"https://github.com/apache/spark/blob/master/examples/src/main/python/wordcount.py\"\n","archive_file_url = \"https://resources.lendingclub.com/LoanStats3a.csv.zip\""],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"session_id":null,"statement_id":null,"state":"waiting","livy_statement_state":null,"queued_time":"2023-10-18T19:31:15.1486086Z","session_start_time":null,"execution_start_time":null,"execution_finish_time":null,"spark_jobs":null,"parent_msg_id":"9c536761-0ddd-456c-9b60-19fe12dad9d5"},"text/plain":"StatementMeta(, , , Waiting, )"},"metadata":{}}],"execution_count":12,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}},"id":"ea4daf70-1e86-41ce-ad27-3bf284e2bcf4"},{"cell_type":"markdown","source":["## Initialize Common Variables for the test run"],"metadata":{"nteract":{"transient":{"deleting":false}}},"id":"68c10945-6b9e-4d5b-9f1c-a16ac3543f1f"},{"cell_type":"code","source":["import time\n","\n","# Don't change these variables\n","TEST_SUITE= \"SPARK_SQL_AUX_STATEMENTS\"\n","RESULT_FILE_NAME=\"aux_stmt_test_result.parquet\"\n","RAW_RESULT_FILE_NAME=\"raw_aux_stmt_test_result.parquet\"\n","# Test Run ID\n","TEST_RUN_ID= round(time.time()*1000)\n","# Test platform\n","PLATFORM = \"nameoftheplatform\"\n","# Prefix for all tables\n","PREFIX = PLATFORM\n","SUFFIX = TEST_RUN_ID\n","# Spark SQL function\n","sql=spark.sql"],"outputs":[],"execution_count":13,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}},"id":"8bd969d7-3e73-4fb1-9a1f-cc8124c7963c"},{"cell_type":"markdown","source":["### Set Common Spark Configurations"],"metadata":{"nteract":{"transient":{"deleting":false}}},"id":"d28f2b7b-1b9a-488e-9fa7-db1603a6ca22"},{"cell_type":"code","source":["sql(\"set hive.exec.dynamic.partition.mode=nonstrict\")"],"outputs":[],"execution_count":14,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}},"id":"0da4030d-69ec-4b20-a810-8106d1c5c875"},{"cell_type":"markdown","source":["### Table Auxiliary Statements - DELTA FORMAT"],"metadata":{"nteract":{"transient":{"deleting":false}}},"id":"0186becc-493c-493e-8e50-ff2e926732da"},{"cell_type":"code","source":["import unittest\n","from pyspark.sql.utils import AnalysisException\n","\n","class AuxDeltaTableStmtTest(unittest.TestCase):\n","    \"\"\"Auxiliary Statements test cases - using delta table\"\"\"\n","    \n","    table_name = f\"{PREFIX}_student_aux_stmt_delta_table_{SUFFIX}\"\n","    view_name = f\"{PREFIX}_student_aux_stmt_delta_table_view_{SUFFIX}\"\n","    cache_table_name = f\"{PREFIX}_student_aux_stmt_delta_table_cache_{SUFFIX}\"\n","      \n","   \n","    @classmethod\n","    def setUpClass(cls):\n","        sql_cmd = f\"CREATE TABLE {cls.table_name} (id INT, name STRING) USING delta PARTITIONED BY (age INT) \\\n","                          TBLPROPERTIES ('created.by.user' = 'Testcases')\"\n","        try:\n","            sql(sql_cmd)\n","            sql(f\"INSERT INTO {cls.table_name} VALUES \\\n","                 (1,'a',10),(2,'b',20),(3,'c',30);\")\n","        except Exception as ex:\n","            msg={'command':'AlterTable:Setup failed','status':'fail'}\n","            cls.fail(f\"{msg}\")\n","\n","    \n","    def test_delta_aux_stmt_001_show_column(self):\n","        \"\"\"Show Columns\"\"\"\n","        sql_cmd = f\"SHOW COLUMNS IN {self.table_name};\"\n","        try:\n","            row_count=sql(sql_cmd).count()\n","            self.assertEqual(row_count,3)\n","        except Exception as ex:\n","            msg={'command':'SHOW COLUMNS for Delta Table','status':'fail'}\n","            self.fail(f\"{msg}\")\n","    \n","    def test_delta_aux_stmt_002_show_create_table_stmt(self):\n","        \"\"\"Show Create Table Statement\"\"\"\n","        sql_cmd = f\"SHOW CREATE TABLE {self.table_name} AS SERDE;\"\n","        try:\n","            row_count=sql(sql_cmd).select(\"createtab_stmt\").count()\n","            self.assertEqual(row_count,1)\n","        except Exception as ex:\n","            msg={'command':'SHOW CREATE TABLE Statement for Delta Table','status':'fail'}\n","            self.fail(f\"{msg}\")\n","\n","    def test_delta_aux_stmt_003_show_partition_table_stmt(self):\n","        \"\"\"Show Partition Table Statement\"\"\"\n","        sql_cmd = f\"SHOW PARTITIONS {self.table_name};\"\n","        try:\n","            row_count=sql(sql_cmd)\n","            self.assertEqual(row_count.select(\"partition\").count(),3)\n","            row_count=sql(f\"SHOW PARTITIONS {self.table_name} PARTITION (age = '10');\").select(\"partition\").count()\n","            self.assertEqual(row_count,1)\n","        except Exception as ex:\n","            msg={'command':'SHOW PARTITIONS Table Statement for Delta Table','status':'fail'}\n","            self.fail(f\"{msg}\")\n","\n","    def test_delta_aux_stmt_004_show_table_extended_stmt(self):\n","        \"\"\"Show Table Extended Table Statement\"\"\"\n","        sql_cmd = f\"SHOW TABLE EXTENDED  LIKE '{self.table_name}';\"\n","        try:\n","            row_count=sql(sql_cmd).select(\"tableName\").count()\n","            self.assertEqual(row_count,1)\n","        except Exception as ex:\n","            msg={'command':'SHOW TABLE EXTENDED LIKE  Statement for Delta Table','status':'fail'}\n","            self.fail(f\"{msg}\")\n","\n","    def test_delta_aux_stmt_005_show_table_extended_partition_stmt(self):\n","        \"\"\"Show Table Extended Table Statement with Partition\"\"\"\n","        sql_cmd = f\"SHOW TABLE EXTENDED  LIKE '{self.table_name}' PARTITION (age=10);\"\n","        try:\n","            row_count=sql(sql_cmd).select(\"tableName\").count()\n","            self.assertEqual(row_count,1)\n","        except Exception as ex:\n","            msg={'command':'SHOW TABLE EXTENDED LIKE PARTITION for Delta Table','status':'fail'}\n","            self.fail(f\"{msg}\")\n","\n","    def test_delta_aux_stmt_006_show_tables_stmt(self):\n","        \"\"\"Show Table Statement\"\"\"\n","        sql_cmd1 = f\"SHOW TABLES;\"\n","        sql_cmd2 = f\"SHOW TABLES LIKE 'student*|test*';\"\n","        try:\n","            row_count=sql(sql_cmd1).select(\"tableName\").count()\n","            self.assertGreaterEqual(row_count,1)\n","            row_count=sql(sql_cmd2).select(\"tableName\").count()\n","            self.assertGreaterEqual(row_count,1)\n","        except Exception as ex:\n","            msg={'command':'SHOW TABLES and SHOW TABLES LIKE for Delta Table','status':'fail'}\n","            self.fail(f\"{msg}\")\n","\n","    def test_delta_aux_stmt_007_show_tables_prop_stmt(self):\n","        \"\"\"Show Table Statement\"\"\"\n","        sql_cmd1 = f\"SHOW TBLPROPERTIES {self.table_name};\"\n","        sql_cmd2 = f\"SHOW TBLPROPERTIES {self.table_name} (created.by.user);\"\n","        try:\n","            row_count=sql(sql_cmd1).select(\"key\").count()\n","            self.assertGreaterEqual(row_count,1)\n","            row_count=sql(sql_cmd2).select(\"value\").count()\n","            self.assertGreaterEqual(row_count,1)\n","        except Exception as ex:\n","            msg={'command':'SHOW TBLPROPERTIES for Delta Table','status':'fail'}\n","            self.fail(f\"{msg}\")\n","    \n","    def test_delta_aux_stmt_008_create_view(self):\n","        \"\"\"create view\"\"\"\n","        sql_cmd = f\"CREATE OR REPLACE VIEW  {self.view_name} (id COMMENT 'ID', name COMMENT 'Name') \\\n","                    COMMENT 'View for student table' \\\n","                    AS SELECT ID,name FROM {self.table_name};\"\n","        try:\n","            sql(sql_cmd)\n","        except Exception as ex:\n","            msg={'command':'CREATE OR REPLACE VIEW for Delta Table','status':'fail'}\n","            self.fail(f\"{msg}\")\n","    \n","    def test_delta_aux_stmt_009_show_view(self):\n","        \"\"\"show view\"\"\"\n","        try:\n","            view_exist=sql(f\"SHOW VIEWS\").filter(f\"viewName='{self.view_name}'\").count()\n","            self.assertEqual(view_exist,1)\n","        except Exception as ex:\n","            msg={'command':'SHOW VIEWS for Delta Table','status':'fail'}\n","            self.fail(f\"{msg}\")\n","\n","    \n","    def test_delta_aux_stmt_010_cache_table_stmt(self):\n","        \"\"\"Cache and UnCache Table\"\"\"\n","        sql_cmd = f\"CACHE TABLE {self.cache_table_name}  OPTIONS ('storageLevel' 'DISK_ONLY') SELECT * FROM {self.table_name}\"\n","        uncache_sql_cmd = f\"UNCACHE TABLE {self.cache_table_name}\"\n","        try:\n","            sql(sql_cmd)\n","            row_count=sql(f\"SELECT * FROM {self.cache_table_name}\").count()\n","            self.assertGreaterEqual(row_count,1)\n","            sql(uncache_sql_cmd)\n","        except Exception as ex:\n","            msg={'command':'CACHE TABLE and UNCACHE TABLE for Delta Table','status':'fail'}\n","            self.fail(f\"{msg}\")\n","\n","    def test_delta_aux_stmt_011_stat_noscan(self):\n","        \"\"\"Delta Table  Analyze Table Compute Statistics NoScan\"\"\"\n","        sql_cmd = f\"ANALYZE TABLE {self.table_name} COMPUTE STATISTICS NOSCAN;\"\n","        try:\n","            sql(sql_cmd)\n","            row_count=sql(f\"DESC EXTENDED {self.table_name}\").where(\"col_name='Statistics'\").count()\n","            self.assertEqual(row_count,1)\n","        except Exception as ex:\n","            msg={'command':'ANALYZE TABLE COMPUTE STATISTICS NOSCAN and DESC EXTENDED for Delta Table','status':'fail'}\n","            self.fail(f\"{msg}\")\n","    \n","    def test_delta_aux_stmt_012_describe_query(self):\n","        \"\"\"Describe query\"\"\"\n","        sql_cmd = f\"DESCRIBE QUERY SELECT age, sum(age) FROM {self.table_name} GROUP BY age;\"\n","        try:\n","            row_count=sql(sql_cmd).select(\"col_name\").count()\n","            self.assertEqual(row_count,2)\n","        except Exception as ex:\n","            msg={'command':'DESCRIBE QUERY for Delta format','status':'fail'}\n","            self.fail(f\"{msg}\")\n","\n","    def test_delta_aux_stmt_012_describe_table(self):\n","        \"\"\"Describe table\"\"\"\n","        sql_cmd = f\"DESCRIBE TABLE {self.table_name}\"\n","        try:\n","            row_count=sql(sql_cmd).select(\"col_name\").count()\n","            self.assertGreaterEqual(row_count,1)\n","        except Exception as ex:\n","            msg={'command':'DESCRIBE QUERY for Delta format','status':'fail'}\n","            self.fail(f\"{msg}\")\n","\n","\n","    @classmethod\n","    def tearDownClass(cls):\n","        \"\"\"tear down\"\"\"\n","        try:\n","            sql(f\"DROP TABLE {cls.table_name}\")\n","        except Exception as e:\n","            print(f\"table drop failed: {cls.table_name}\")\n","\n","        try:\n","            sql(f\"DROP TABLE {cls.cache_table_name}\")\n","        except Exception as e:\n","            print(f\"table drop failed: {cls.cache_table_name}\")\n","        \n","        try:\n","            sql(f\"DROP VIEW {cls.view_name}\")\n","        except Exception as e:\n","            print(f\"View drop failed: {cls.view_name}\")"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"session_id":null,"statement_id":null,"state":"waiting","livy_statement_state":null,"queued_time":"2023-10-18T19:31:15.6123798Z","session_start_time":null,"execution_start_time":null,"execution_finish_time":null,"spark_jobs":null,"parent_msg_id":"b22c65cd-7f8b-4d7a-8f0a-4a1f0dda1b6e"},"text/plain":"StatementMeta(, , , Waiting, )"},"metadata":{}}],"execution_count":15,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}},"id":"deca79cf-3add-4981-8c20-91eec3b988ca"},{"cell_type":"markdown","source":["### Table Auxiliary Statements - DEFAULT FORMAT"],"metadata":{"nteract":{"transient":{"deleting":false}}},"id":"278ae08c-3f73-4682-b9eb-3817aae8ef26"},{"cell_type":"code","source":["import unittest\n","from pyspark.sql.utils import AnalysisException\n","\n","class AuxTableStmtTest(unittest.TestCase):\n","    \"\"\"Auxiliary Statements test cases - using default format\"\"\"\n","    \n","    table_name = f\"{PREFIX}_student_aux_stmt_default_table_{SUFFIX}\"\n","    view_name = f\"{PREFIX}_student_aux_stmt_default_table_view_{SUFFIX}\"\n","    cache_table_name = f\"{PREFIX}_student_aux_stmt_default_table_cache_{SUFFIX}\"\n","      \n","   \n","    @classmethod\n","    def setUpClass(cls):\n","        sql_cmd = f\"CREATE TABLE {cls.table_name} (id INT, name STRING) PARTITIONED BY (age INT) \\\n","                          TBLPROPERTIES ('created.by.user' = 'Testcases')\"\n","        try:\n","            sql(sql_cmd)\n","            sql(f\"INSERT INTO {cls.table_name} VALUES \\\n","                 (1,'a',10),(2,'b',20),(3,'c',30);\")\n","        except Exception as ex:\n","            msg={'command':'AlterTable:Setup failed','status':'fail'}\n","            cls.fail(f\"{msg}\")\n","\n","    \n","    def test_default_aux_stmt_001_show_column(self):\n","        \"\"\"Show Columns\"\"\"\n","        sql_cmd = f\"SHOW COLUMNS IN {self.table_name};\"\n","        try:\n","            row_count=sql(sql_cmd).count()\n","            self.assertEqual(row_count,3)\n","        except Exception as ex:\n","            msg={'command':'SHOW COLUMNS for Default format','status':'fail'}\n","            self.fail(f\"{msg}\")\n","    \n","    def test_default_aux_stmt_002_show_create_table_stmt(self):\n","        \"\"\"Show Create Table Statement\"\"\"\n","        sql_cmd = f\"SHOW CREATE TABLE {self.table_name} AS SERDE;\"\n","        try:\n","            row_count=sql(sql_cmd).select(\"createtab_stmt\").count()\n","            self.assertEqual(row_count,1)\n","        except Exception as ex:\n","            msg={'command':'SHOW CREATE TABLE Statement for Default format','status':'fail'}\n","            self.fail(f\"{msg}\")\n","\n","    def test_default_aux_stmt_003_show_partition_table_stmt(self):\n","        \"\"\"Show Partition Table Statement\"\"\"\n","        sql_cmd = f\"SHOW PARTITIONS {self.table_name};\"\n","        try:\n","            row_count=sql(sql_cmd)\n","            self.assertEqual(row_count.select(\"partition\").count(),3)\n","            row_count=sql(f\"SHOW PARTITIONS {self.table_name} PARTITION (age = '10');\").select(\"partition\").count()\n","            self.assertEqual(row_count,1)\n","        except Exception as ex:\n","            msg={'command':'SHOW PARTITIONS Table Statement for Default format','status':'fail'}\n","            self.fail(f\"{msg}\")\n","\n","    def test_default_aux_stmt_004_show_table_extended_stmt(self):\n","        \"\"\"Show Table Extended Table Statement\"\"\"\n","        sql_cmd = f\"SHOW TABLE EXTENDED  LIKE '{self.table_name}';\"\n","        try:\n","            row_count=sql(sql_cmd).select(\"tableName\").count()\n","            self.assertEqual(row_count,1)\n","        except Exception as ex:\n","            msg={'command':'SHOW TABLE EXTENDED LIKE  Statement for Delta Table','status':'fail'}\n","            self.fail(f\"{msg}\")\n","\n","    def test_default_aux_stmt_005_show_table_extended_partition_stmt(self):\n","        \"\"\"Show Table Extended Table Statement with Partition\"\"\"\n","        sql_cmd = f\"SHOW TABLE EXTENDED  LIKE '{self.table_name}' PARTITION (age=10);\"\n","        try:\n","            row_count=sql(sql_cmd).select(\"tableName\").count()\n","            self.assertEqual(row_count,1)\n","        except Exception as ex:\n","            msg={'command':'SHOW TABLE EXTENDED LIKE PARTITION for Default format','status':'fail'}\n","            self.fail(f\"{msg}\")\n","\n","    def test_default_aux_stmt_006_show_tables_stmt(self):\n","        \"\"\"Show Table Statement\"\"\"\n","        sql_cmd1 = f\"SHOW TABLES;\"\n","        sql_cmd2 = f\"SHOW TABLES LIKE 'student*|test*';\"\n","        try:\n","            row_count=sql(sql_cmd1).select(\"tableName\").count()\n","            self.assertGreaterEqual(row_count,1)\n","            row_count=sql(sql_cmd2).select(\"tableName\").count()\n","            self.assertGreaterEqual(row_count,1)\n","        except Exception as ex:\n","            msg={'command':'SHOW TABLES and SHOW TABLES LIKE for Default format','status':'fail'}\n","            self.fail(f\"{msg}\")\n","\n","    def test_default_aux_stmt_007_show_tables_prop_stmt(self):\n","        \"\"\"Show Table Statement\"\"\"\n","        sql_cmd1 = f\"SHOW TBLPROPERTIES {self.table_name};\"\n","        sql_cmd2 = f\"SHOW TBLPROPERTIES {self.table_name} (created.by.user);\"\n","        try:\n","            row_count=sql(sql_cmd1).select(\"key\").count()\n","            self.assertGreaterEqual(row_count,1)\n","            row_count=sql(sql_cmd2).select(\"value\").count()\n","            self.assertGreaterEqual(row_count,1)\n","        except Exception as ex:\n","            msg={'command':'SHOW TBLPROPERTIES for Default format','status':'fail'}\n","            self.fail(f\"{msg}\")\n","    \n","    def test_default_aux_stmt_008_create_view(self):\n","        \"\"\"create view\"\"\"\n","        sql_cmd = f\"CREATE OR REPLACE VIEW  {self.view_name} (id COMMENT 'ID', name COMMENT 'Name') \\\n","                    COMMENT 'View for student table' \\\n","                    AS SELECT ID,name FROM {self.table_name};\"\n","        try:\n","            sql(sql_cmd)\n","        except Exception as ex:\n","            msg={'command':'CREATE OR REPLACE VIEW for Default format','status':'fail'}\n","            self.fail(f\"{msg}\")\n","    \n","    def test_default_aux_stmt_009_show_view(self):\n","        \"\"\"show view\"\"\"\n","        try:\n","            view_exist=sql(f\"SHOW VIEWS\").filter(f\"viewName='{self.view_name}'\").count()\n","            self.assertEqual(view_exist,1)\n","        except Exception as ex:\n","            msg={'command':'SHOW VIEWS for Default format','status':'fail'}\n","            self.fail(f\"{msg}\")\n","\n","    \n","    def test_default_aux_stmt_010_cache_table_stmt(self):\n","        \"\"\"Cache and UnCache Table\"\"\"\n","        sql_cmd = f\"CACHE TABLE {self.cache_table_name}  OPTIONS ('storageLevel' 'DISK_ONLY') SELECT * FROM {self.table_name}\"\n","        uncache_sql_cmd = f\"UNCACHE TABLE {self.cache_table_name}\"\n","        try:\n","            sql(sql_cmd)\n","            row_count=sql(f\"SELECT * FROM {self.cache_table_name}\").count()\n","            self.assertGreaterEqual(row_count,1)\n","            sql(uncache_sql_cmd)\n","        except Exception as ex:\n","            msg={'command':'CACHE TABLE and UNCACHE TABLE for Default format','status':'fail'}\n","            self.fail(f\"{msg}\")\n","\n","    def test_default_aux_stmt_011_stat_noscan(self):\n","        \"\"\"Analyze Table Compute Statistics NoScan\"\"\"\n","        sql_cmd = f\"ANALYZE TABLE {self.table_name} COMPUTE STATISTICS NOSCAN;\"\n","        try:\n","            sql(sql_cmd)\n","            row_count=sql(f\"DESC EXTENDED {self.table_name}\").where(\"col_name='Statistics'\").count()\n","            self.assertEqual(row_count,1)\n","        except Exception as ex:\n","            msg={'command':'ANALYZE TABLE COMPUTE STATISTICS NOSCAN and DESC EXTENDED for Default format','status':'fail'}\n","            self.fail(f\"{msg}\")\n","\n","    def test_default_aux_stmt_012_describe_query(self):\n","        \"\"\"Describe query\"\"\"\n","        sql_cmd = f\"DESCRIBE QUERY SELECT age, sum(age) FROM {self.table_name} GROUP BY age;\"\n","        try:\n","            row_count=sql(sql_cmd).select(\"col_name\").count()\n","            self.assertEqual(row_count,2)\n","        except Exception as ex:\n","            msg={'command':'DESCRIBE QUERY for Default format','status':'fail'}\n","            self.fail(f\"{msg}\")\n","\n","    @classmethod\n","    def tearDownClass(cls):\n","        \"\"\"tear down\"\"\"\n","        try:\n","            sql(f\"DROP TABLE {cls.table_name}\")\n","        except Exception as e:\n","            print(f\"table drop failed: {cls.table_name}\")\n","\n","        try:\n","            sql(f\"DROP TABLE {cls.cache_table_name}\")\n","        except Exception as e:\n","            print(f\"table drop failed: {cls.cache_table_name}\")\n","        \n","        try:\n","            sql(f\"DROP VIEW {cls.view_name}\")\n","        except Exception as e:\n","            print(f\"View drop failed: {cls.view_name}\")"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"session_id":null,"statement_id":null,"state":"waiting","livy_statement_state":null,"queued_time":"2023-10-18T19:31:15.8364782Z","session_start_time":null,"execution_start_time":null,"execution_finish_time":null,"spark_jobs":null,"parent_msg_id":"8395643f-52d6-4318-855d-5b223407321c"},"text/plain":"StatementMeta(, , , Waiting, )"},"metadata":{}}],"execution_count":16,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}},"id":"e8d2e70e-171e-4734-8a00-6bf41e9567a8"},{"cell_type":"markdown","source":["### Analyze Table Statements\n","\n","**Analyze Tables is <mark>not supported for V2 tables.**"],"metadata":{"nteract":{"transient":{"deleting":false}}},"id":"d80ba8dd-4bd4-4692-8090-99c6f733541c"},{"cell_type":"code","source":["import unittest\n","from pyspark.sql.utils import AnalysisException\n","\n","class AnalyzeTableStmtTest(unittest.TestCase):\n","    \"\"\"Analyze Table Statements test cases for Non Delta Tables\"\"\"\n","    \n","    table_name = f\"{PREFIX}_student_analyze_table_{SUFFIX}\"   \n","   \n","    @classmethod\n","    def setUpClass(cls):\n","        sql_cmd = f\"CREATE TABLE {cls.table_name} (id INT, name STRING) PARTITIONED BY (age INT) \\\n","                          TBLPROPERTIES ('created.by.user' = 'Testcases')\"\n","        try:\n","            sql(sql_cmd)\n","            sql(f\"INSERT INTO {cls.table_name} VALUES \\\n","                 (1,'a',10),(2,'b',20),(3,'c',30);\")\n","        except Exception as ex:\n","            msg={'command':'AnalyzeTable:Setup failed','status':'fail'}\n","            cls.fail(f\"{msg}\")\n","\n","    \n","    def test_analyze_table_stmt_001_stat_partition(self):\n","        \"\"\"Analyze Table Compute Statistics with partition\"\"\"\n","        sql_cmd = f\"ANALYZE TABLE {self.table_name} PARTITION (age=10) COMPUTE STATISTICS;\"\n","        try:\n","            sql(sql_cmd)\n","            row_count=sql(f\"DESC EXTENDED {self.table_name} PARTITION (age=10)\").where(\"col_name='Partition Statistics'\").count()\n","            self.assertEqual(row_count,1)\n","        except Exception as ex:\n","            msg={'command':'ANALYZE TABLE PARTITION COMPUTE STATISTICS for default format','status':'fail'}\n","            self.fail(f\"{msg}\")\n","    \n","    def test_analyze_table_stmt_002_stat_for_columns(self):\n","        \"\"\"Analyze Table Compute Statistics for Columns\"\"\"\n","        sql_cmd = f\"ANALYZE TABLE {self.table_name} COMPUTE STATISTICS FOR COLUMNS name\"\n","        try:\n","            sql(sql_cmd)\n","            row_count=sql(f\"DESC EXTENDED {self.table_name} name\").where(\"info_name='col_name'\").count()\n","            self.assertEqual(row_count,1)\n","        except Exception as ex:\n","            msg={'command':'ANALYZE TABLE COMPUTE STATISTICS FOR COLUMNS for default format','status':'fail'}\n","            self.fail(f\"{msg}\")\n","    \n","\n","    @classmethod\n","    def tearDownClass(cls):\n","        \"\"\"tear down\"\"\"\n","        try:\n","            sql(f\"DROP TABLE {cls.table_name}\")\n","        except Exception as e:\n","            print(f\"table drop failed: {cls.table_name}\")"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"session_id":null,"statement_id":null,"state":"waiting","livy_statement_state":null,"queued_time":"2023-10-18T19:31:16.0444768Z","session_start_time":null,"execution_start_time":null,"execution_finish_time":null,"spark_jobs":null,"parent_msg_id":"1628fb0b-db28-41bf-95a6-e9b3fb0fc60a"},"text/plain":"StatementMeta(, , , Waiting, )"},"metadata":{}}],"execution_count":17,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}},"id":"dfa92b3c-0343-4796-b7e3-8dda8f2b9831"},{"cell_type":"markdown","source":["### Miscellaneous Auxiliary Statements"],"metadata":{"nteract":{"transient":{"deleting":false}}},"id":"6a2c5276-ec94-424b-b002-9fe970f06c20"},{"cell_type":"code","source":["import unittest\n","from pyspark.sql.utils import AnalysisException\n","\n","class AuxMiscStmtTest(unittest.TestCase):\n","    \"\"\"Auxiliary miscellaneous Statements\"\"\"\n","    \n","   \n","    def test_aux_stmt_001_show_schema(self):\n","        \"\"\"Show Schema\"\"\"\n","        sql_cmd = f\"SHOW SCHEMAS;\"\n","        try:\n","            row_count=sql(sql_cmd).count()\n","            self.assertGreaterEqual(row_count,0)\n","        except Exception as ex:\n","            msg={'command':'SHOW SCHEMAS','status':'fail'}\n","            self.fail(f\"{msg}\")\n","    \n","    def test_aux_stmt_001_show_databases(self):\n","        \"\"\"Show Databases\"\"\"\n","        sql_cmd = f\"SHOW DATABASES;\"\n","        try:\n","            row_count=sql(sql_cmd).count()\n","            self.assertGreaterEqual(row_count,1)\n","        except Exception as ex:\n","            msg={'command':'SHOW DATABASES','status':'fail'}\n","            self.fail(f\"{msg}\")   \n","\n","    def test_aux_stmt_002_desc_databases(self):\n","        \"\"\"describe Databases\"\"\"\n","        sql_cmd = f\"SHOW DATABASES;\"\n","        msg={'command':'DESC DATABASE','status':'fail'}\n","        try:\n","            databases=sql(sql_cmd).select('namespace').rdd.flatMap(lambda x: x).collect()\n","            if len(databases)>0:\n","                row_count=sql(f\"DESC DATABASE {databases[0]}\").where(f\"info_value='{databases[0]}'\").count()\n","                self.assertEqual(row_count,1)\n","            else:\n","                self.fail(f\"{msg}\")  \n","        except Exception as ex:\n","            self.fail(f\"{msg}\")   \n","\n","    #sql(\"SHOW DATABASES\").select('namespace').rdd.flatMap(lambda x: x).collect()\n","    def test_aux_stmt_003_show_functions(self):\n","        \"\"\"Show Functions\"\"\"\n","        sql_cmd = f\"SHOW FUNCTIONS explode;\"\n","        try:\n","            row_count=sql(sql_cmd).count()\n","            self.assertEqual(row_count,1)\n","            row_count=sql(\"SHOW FUNCTIONS LIKE 't*'\").count()\n","            self.assertGreaterEqual(row_count,1)\n","            row_count = sql(\"SHOW FUNCTIONS LIKE 'yea*|windo*'\").count()\n","            self.assertGreaterEqual(row_count,1)\n","        except Exception as ex:\n","            msg={'command':'SHOW FUNCTIONS and SHOW FUNCTIONS LIKE','status':'fail'}\n","            self.fail(f\"{msg}\")   \n","\n","    def test_aux_stmt_004_desc_functions(self):\n","        \"\"\"describe functions\"\"\"\n","        sql_cmd = f\"DESC FUNCTION EXTENDED abs\"\n","        try:\n","            row_count=sql(sql_cmd).select('function_desc').count()\n","            self.assertGreaterEqual(row_count,1)\n","        except Exception as ex:\n","            msg={'command':'DESC FUNCTION','status':'fail'}\n","            self.fail(f\"{msg}\")   \n","\n","    def test_aux_stmt_005_add_list_jar(self):\n","        \"\"\"Add and List Jar Statement\"\"\"\n","        sql_cmd1 = f\"ADD JAR {add_jar_url}\"\n","        sql_cmd2= f\"LIST JAR {add_jar_url}\"\n","        try:\n","            sql(sql_cmd1)\n","            row_count=sql(sql_cmd2).count()\n","            self.assertGreaterEqual(row_count,1)\n","        except Exception as ex:\n","            msg={'command':'ADD JAR and LIST JAR','status':'fail'}\n","            self.fail(f\"{msg}\")   \n","\n","    def test_aux_stmt_006_add_file(self):\n","        \"\"\"Add and List File Statement\"\"\"\n","        sql_cmd1 = f\"ADD FILE {add_file_url}\"\n","        sql_cmd2= f\"LIST FILE {add_file_url}\"\n","        try:\n","            sql(sql_cmd1)\n","            row_count=sql(sql_cmd2).count()\n","            self.assertGreaterEqual(row_count,1)\n","        except Exception as ex:\n","            msg={'command':'ADD FILE and LIST FILE','status':'fail'}\n","            self.fail(f\"{msg}\")   \n","\n","    def test_aux_stmt_007_add_archive_file(self):\n","        \"\"\"Add and List File Statement\"\"\"\n","        sql_cmd1 = f\"ADD ARCHIVE {archive_file_url}\"\n","        sql_cmd2= f\"LIST ARCHIVE {archive_file_url}\"\n","        try:\n","            sql(sql_cmd1)\n","            row_count=sql(sql_cmd2).count()\n","            self.assertGreaterEqual(row_count,1)\n","        except Exception as ex:\n","            msg={'command':'ADD ARCHIVE and LIST ARCHIVE','status':'fail'}\n","            self.fail(f\"{msg}\")   \n"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"session_id":null,"statement_id":null,"state":"waiting","livy_statement_state":null,"queued_time":"2023-10-18T19:31:16.2576966Z","session_start_time":null,"execution_start_time":null,"execution_finish_time":null,"spark_jobs":null,"parent_msg_id":"026a2ff5-4139-4e00-9040-83e6f61645a5"},"text/plain":"StatementMeta(, , , Waiting, )"},"metadata":{}}],"execution_count":18,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}},"id":"61d12a7f-874d-42fe-9e46-047b5c963017"},{"cell_type":"markdown","source":["### Execute Test Cases"],"metadata":{"nteract":{"transient":{"deleting":false}}},"id":"db2461a1-aa19-4e29-8166-c5f3c23f4844"},{"cell_type":"code","source":["import io\n","import xmlrunner\n","loader = unittest.TestLoader()\n","suite  = unittest.TestSuite()\n","\n","# add tests to the test suite\n","suite.addTests(loader.loadTestsFromTestCase(AnalyzeTableStmtTest))\n","suite.addTests(loader.loadTestsFromTestCase(AuxDeltaTableStmtTest))\n","suite.addTest(loader.loadTestsFromTestCase(AuxMiscStmtTest))\n","suite.addTest(loader.loadTestsFromTestCase(AnalyzeTableStmtTest))\n","\n","# initialize a runner, pass it your suite and run it\n","out = io.BytesIO()\n","runner = xmlrunner.XMLTestRunner(output=out)\n","result = runner.run(suite)"],"outputs":[],"execution_count":19,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}},"id":"4ecaea0c-11ab-4101-a0a6-a6bf2d14b664"},{"cell_type":"markdown","source":["## Report for Test"],"metadata":{"nteract":{"transient":{"deleting":false}}},"id":"b5893dd7-fb26-4d4b-b735-7e25d8fd1b05"},{"cell_type":"code","source":["from pyspark.sql.functions import when,col, explode,isnull,from_json\n","from pyspark.sql.types import StructType,StructField,StringType\n","import json\n","import xmltodict\n","\n","# convert xml to dict / json\n","dict_result=xmltodict.parse(out.getvalue())\n","json_result = json.loads(json.dumps(dict_result,indent=4).replace('@',''))\n","test_suites=json_result['testsuites']['testsuite']\n","\n","# create dataframe\n","df = spark.read.json(sc.parallelize([test_suites]))\n","\n","fail_schema = StructType([\n","  StructField(\"command\", StringType(), True),\n","  StructField(\"status\", StringType(),  True)\n","])\n","\n","explode_df= df.withColumn('ts',explode('testcase')).withColumn('fail',from_json(col('ts.failure.message'),fail_schema)).drop(col('testcase')).drop(col('ts.failure'))\n","\n","df_test_result=explode_df.select(col(\"errors\").alias(\"errorInSuite\"),col(\"failures\").alias(\"failedInSuite\"),col(\"name\").alias(\"suitename\"),\"skipped\",col(\"tests\").alias(\"totalTest\"),col(\"timestamp\").alias(\"executionTime\"),col(\"ts.name\").alias(\"testCaseName\"),col(\"ts.time\").alias(\"testCaseTime\"),col(\"fail.command\"))\n","\n","if (len(storage_account)>0 and len(result_container)>0):\n","    # save result to storage\n","    storage_path = f\"abfs://{result_container}@{storage_account}.dfs.core.windows.net/{TEST_RUN_ID}/{PLATFORM}/{TEST_SUITE}\"\n","    # write raw results\n","    df.write.parquet(f\"{storage_path}/{RAW_RESULT_FILE_NAME}\")\n","    # write transformed results\n","    df_test_result.write.parquet(f\"{storage_path}/{RESULT_FILE_NAME}\") \n","else:\n","    print(\"configure storage path to store results\")\n","    df_test_result.show(100,False)   "],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}},"id":"85903935-6884-48be-ae4a-956b42d5f82d"},{"cell_type":"code","source":[],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}},"id":"3bb81434-1146-4d7a-b3b6-3645f6a0e373"}],"metadata":{"language_info":{"name":"python"},"kernelspec":{"name":"synapse_pyspark","language":"Python","display_name":"Synapse PySpark"},"microsoft":{"host":{},"language":"python"},"widgets":{},"kernel_info":{"name":"synapse_pyspark"},"nteract":{"version":"nteract-front-end@1.0.0"},"save_output":true,"spark_compute":{"compute_id":"/trident/default","session_options":{"enableDebugMode":false,"conf":{}}},"notebook_environment":{},"synapse_widget":{"version":"0.1","state":{}},"trident":{"lakehouse":{"known_lakehouses":[{"id":"99940866-4aa4-4893-98d1-1e698b9365f7"}],"default_lakehouse":"99940866-4aa4-4893-98d1-1e698b9365f7","default_lakehouse_name":"mdfsparkdemo","default_lakehouse_workspace_id":"0efc371e-81be-4375-8e61-b5a2cadfabce"}}},"nbformat":4,"nbformat_minor":5}